{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOrIIttIlkw3hCk33I6O47C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import string\nimport numpy as np\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\nfrom keras.models import Model\nfrom keras.layers import LSTM, Input, TimeDistributed, Dense,Activation, RepeatVector, Embedding\nfrom keras.optimizers import Adam\nfrom keras.losses import sparse_categorical_crossentropy","metadata":{"id":"dKC2VgAfT2Iv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib\n\npath_to_zip = tf.keras.utils.get_file(\n    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n    extract=True)\n\npath_to_data = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hHDDS9LHT_B0","executionInfo":{"status":"ok","timestamp":1698935156324,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Mayank Gujrathi","userId":"02033393095614692435"}},"outputId":"9dc8422f-b769-4b97-8fe7-8add617f1c8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n\n2638744/2638744 [==============================] - 1s 0us/step\n"}]},{"cell_type":"code","source":"translation_file = open(path_to_data,\"r\", encoding='utf-8')\nraw_data = translation_file.read()\ntranslation_file.close()","metadata":{"id":"ykJWuADvT1_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data = raw_data.split('\\n')\npairs = [sentence.split('\\t') for sentence in raw_data]\npairs = pairs[1000:20000]","metadata":{"id":"HPmqvCdCT11P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_sentence(sentence):\n  # Lower case the sentence\n  lower_case_sent = sentence.lower() # Strip punctuation\n  string_punctuation = string.punctuation + \"¡\" + '¿'\n  clean_sentence = lower_case_sent.translate(str.maketrans('', '', string_punctuation))\n  return clean_sentence\n\ndef tokenize(sentences): # Create tokenizer\n  text_tokenizer = Tokenizer() # Fit texts\n  text_tokenizer.fit_on_texts(sentences)\n  return text_tokenizer.texts_to_sequences(sentences), text_tokenizer\n\nenglish_sentences = [clean_sentence(pair[0]) for pair in pairs]\nspanish_sentences = [clean_sentence(pair[1]) for pair in pairs]","metadata":{"id":"_oHShWFVVD0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize words\nspa_text_tokenized, spa_text_tokenizer = tokenize(spanish_sentences)\neng_text_tokenized, eng_text_tokenizer = tokenize(english_sentences)\n\nprint('Maximum length spanish sentence: {}'.format(len(max(spa_text_tokenized,key=len))))\nprint('Maximum length english sentence: {}'.format(len(max(eng_text_tokenized,key=len))))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAkyEsb5Vnt3","executionInfo":{"status":"ok","timestamp":1698935157998,"user_tz":-330,"elapsed":881,"user":{"displayName":"Mayank Gujrathi","userId":"02033393095614692435"}},"outputId":"62a3678a-b919-489e-925d-17b3ee3a9a7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Maximum length spanish sentence: 12\n\nMaximum length english sentence: 6\n"}]},{"cell_type":"code","source":"# Check language length\nspanish_vocab = len(spa_text_tokenizer.word_index) + 1\nenglish_vocab = len(eng_text_tokenizer.word_index) + 1\nprint(\"Spanish vocabulary is of {} unique words\".format(spanish_vocab))\nprint(\"English vocabulary is of {} unique words\".format(english_vocab))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SG2DiLEFV-eJ","executionInfo":{"status":"ok","timestamp":1698935157999,"user_tz":-330,"elapsed":19,"user":{"displayName":"Mayank Gujrathi","userId":"02033393095614692435"}},"outputId":"bc9fd87f-2734-400f-c145-e2a9dec3f187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Spanish vocabulary is of 7239 unique words\n\nEnglish vocabulary is of 3804 unique words\n"}]},{"cell_type":"code","source":"max_spanish_len = int(len(max(spa_text_tokenized,key=len)))\nmax_english_len = int(len(max(eng_text_tokenized,key=len)))\nspa_pad_sentence = pad_sequences(spa_text_tokenized, max_spanish_len, padding = \"post\")\neng_pad_sentence = pad_sequences(eng_text_tokenized, max_english_len, padding = \"post\")","metadata":{"id":"b5G8NEFRWENL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshape data\nspa_pad_sentence = spa_pad_sentence.reshape(*spa_pad_sentence.shape, 1)\neng_pad_sentence = eng_pad_sentence.reshape(*eng_pad_sentence.shape, 1)","metadata":{"id":"MIx1CJgLWNNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_sequence = Input(shape=(max_spanish_len,))\n# embedding = Embedding(input_dim=spanish_vocab, output_dim=128,)(input_sequence)","metadata":{"id":"ON1zWJ8mT1uo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_sequence = Input(shape=(max_spanish_len,))\n# embedding = Embedding(input_dim=spanish_vocab, output_dim=128,)(input_sequence)\n# encoder = LSTM(64, return_sequences=False)(embedding)","metadata":{"id":"tD2QbMsyWY_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_sequence = Input(shape=(max_spanish_len,))\n# embedding = Embedding(input_dim=spanish_vocab, output_dim=128,)(input_sequence)\n# encoder = LSTM(64, return_sequences=False)(embedding)\n# r_vec = RepeatVector(max_english_len)(encoder)","metadata":{"id":"ktebwd9nWiLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_sequence = Input(shape=(max_spanish_len,))\n# embedding = Embedding(input_dim=spanish_vocab, output_dim=128,)(input_sequence)\n# encoder = LSTM(64, return_sequences=False)(embedding)\n# r_vec = RepeatVector(max_english_len)(encoder)\n# decoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)","metadata":{"id":"iLPK17ZDWY08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sequence = Input(shape=(max_spanish_len,))\nembedding = Embedding(input_dim=spanish_vocab, output_dim=128,)(input_sequence)\nencoder = LSTM(64, return_sequences=False)(embedding)\nr_vec = RepeatVector(max_english_len)(encoder)\ndecoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)\nlogits = TimeDistributed(Dense(english_vocab))(decoder)\nenc_dec_model = Model(input_sequence, Activation('softmax')(logits))\nenc_dec_model.compile(loss=sparse_categorical_crossentropy, optimizer=Adam(1e-3), metrics=['accuracy'])\nenc_dec_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G6OYmA-9WYr5","executionInfo":{"status":"ok","timestamp":1698935164269,"user_tz":-330,"elapsed":6280,"user":{"displayName":"Mayank Gujrathi","userId":"02033393095614692435"}},"outputId":"d73ff6e8-38e3-44f6-9c6f-74fdf909e172"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"model\"\n\n_________________________________________________________________\n\n Layer (type)                Output Shape              Param #   \n\n=================================================================\n\n input_1 (InputLayer)        [(None, 12)]              0         \n\n                                                                 \n\n embedding (Embedding)       (None, 12, 128)           926592    \n\n                                                                 \n\n lstm (LSTM)                 (None, 64)                49408     \n\n                                                                 \n\n repeat_vector (RepeatVecto  (None, 6, 64)             0         \n\n r)                                                              \n\n                                                                 \n\n lstm_1 (LSTM)               (None, 6, 64)             33024     \n\n                                                                 \n\n time_distributed (TimeDist  (None, 6, 3804)           247260    \n\n ributed)                                                        \n\n                                                                 \n\n activation (Activation)     (None, 6, 3804)           0         \n\n                                                                 \n\n=================================================================\n\nTotal params: 1256284 (4.79 MB)\n\nTrainable params: 1256284 (4.79 MB)\n\nNon-trainable params: 0 (0.00 Byte)\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"enc_dec_model.fit(spa_pad_sentence, eng_pad_sentence, epochs=50)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYiFIiiJYy0D","executionInfo":{"status":"ok","timestamp":1698935433397,"user_tz":-330,"elapsed":269145,"user":{"displayName":"Mayank Gujrathi","userId":"02033393095614692435"}},"outputId":"1ed22b8f-7554-4791-de57-670755cf0e5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/50\n\n594/594 [==============================] - 22s 13ms/step - loss: 4.1397 - accuracy: 0.4329\n\nEpoch 2/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 3.5077 - accuracy: 0.4647\n\nEpoch 3/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 3.4407 - accuracy: 0.4648\n\nEpoch 4/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 3.4119 - accuracy: 0.4648\n\nEpoch 5/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 3.3954 - accuracy: 0.4648\n\nEpoch 6/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 3.3840 - accuracy: 0.4647\n\nEpoch 7/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 3.3485 - accuracy: 0.4683\n\nEpoch 8/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 3.2676 - accuracy: 0.4738\n\nEpoch 9/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 3.1798 - accuracy: 0.4803\n\nEpoch 10/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 3.0158 - accuracy: 0.4977\n\nEpoch 11/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 2.8717 - accuracy: 0.5135\n\nEpoch 12/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 2.7563 - accuracy: 0.5251\n\nEpoch 13/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 2.6409 - accuracy: 0.5388\n\nEpoch 14/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 2.5186 - accuracy: 0.5542\n\nEpoch 15/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 2.4028 - accuracy: 0.5675\n\nEpoch 16/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 2.2946 - accuracy: 0.5807\n\nEpoch 17/50\n\n594/594 [==============================] - 5s 9ms/step - loss: 2.1991 - accuracy: 0.5929\n\nEpoch 18/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 2.1129 - accuracy: 0.6041\n\nEpoch 19/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 2.0334 - accuracy: 0.6127\n\nEpoch 20/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.9558 - accuracy: 0.6222\n\nEpoch 21/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.8873 - accuracy: 0.6307\n\nEpoch 22/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 1.8202 - accuracy: 0.6389\n\nEpoch 23/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.7554 - accuracy: 0.6474\n\nEpoch 24/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.6963 - accuracy: 0.6554\n\nEpoch 25/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 1.6372 - accuracy: 0.6624\n\nEpoch 26/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.5764 - accuracy: 0.6713\n\nEpoch 27/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.5240 - accuracy: 0.6785\n\nEpoch 28/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 1.4699 - accuracy: 0.6875\n\nEpoch 29/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.4220 - accuracy: 0.6928\n\nEpoch 30/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 1.3747 - accuracy: 0.7002\n\nEpoch 31/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.3267 - accuracy: 0.7080\n\nEpoch 32/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.2798 - accuracy: 0.7147\n\nEpoch 33/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 1.2356 - accuracy: 0.7222\n\nEpoch 34/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.1928 - accuracy: 0.7299\n\nEpoch 35/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.1549 - accuracy: 0.7366\n\nEpoch 36/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 1.1162 - accuracy: 0.7432\n\nEpoch 37/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.0781 - accuracy: 0.7506\n\nEpoch 38/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 1.0406 - accuracy: 0.7580\n\nEpoch 39/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 1.0090 - accuracy: 0.7655\n\nEpoch 40/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 0.9749 - accuracy: 0.7703\n\nEpoch 41/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 0.9414 - accuracy: 0.7776\n\nEpoch 42/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 0.9122 - accuracy: 0.7834\n\nEpoch 43/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 0.8809 - accuracy: 0.7907\n\nEpoch 44/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 0.8538 - accuracy: 0.7965\n\nEpoch 45/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 0.8288 - accuracy: 0.8019\n\nEpoch 46/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 0.8015 - accuracy: 0.8074\n\nEpoch 47/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 0.7764 - accuracy: 0.8129\n\nEpoch 48/50\n\n594/594 [==============================] - 4s 7ms/step - loss: 0.7571 - accuracy: 0.8169\n\nEpoch 49/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 0.7330 - accuracy: 0.8214\n\nEpoch 50/50\n\n594/594 [==============================] - 5s 8ms/step - loss: 0.7120 - accuracy: 0.8269\n"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":["<keras.src.callbacks.History at 0x7ca0e81f4ac0>"]},"metadata":{}}]},{"cell_type":"code","source":"def logits_to_sentence(logits, tokenizer):\n  index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n  index_to_words[0] = '<empty>'\n  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n\nindexes = [1, 17]\nfor index in indexes:\n  print(\"The english sentence is: {}\".format(english_sentences[index]))\n  print(\"The spanish sentence is: {}\".format(spanish_sentences[index]))\n  print('The predicted sentence is :')\n  print(logits_to_sentence(enc_dec_model.predict(spa_pad_sentence[index:index+1])[0], eng_text_tokenizer))\n  print()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xk11QNDkXAhJ","executionInfo":{"status":"ok","timestamp":1698935433397,"user_tz":-330,"elapsed":28,"user":{"displayName":"Mayank Gujrathi","userId":"02033393095614692435"}},"outputId":"fffb14a7-1a37-42d9-987d-25103c661c7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"The english sentence is: he is here\n\nThe spanish sentence is: él está aquí\n\nThe predicted sentence is :\n\n1/1 [==============================] - 1s 618ms/step\n\nhe is here <empty> <empty> <empty>\n\n\n\nThe english sentence is: hes smart\n\nThe spanish sentence is: él es inteligente\n\nThe predicted sentence is :\n\n1/1 [==============================] - 0s 16ms/step\n\nhes intelligent <empty> <empty> <empty> <empty>\n\n\n"}]}]}